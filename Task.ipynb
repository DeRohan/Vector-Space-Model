{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Processing the Research Papers and Stop Words.\n",
    "import glob as gb\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "document_list = defaultdict(str)\n",
    "directory = 'ResearchPapers/' #Directory Name\n",
    "originals = set() #List of all Document IDs to be used in Query Processing\n",
    "total_docs = 0\n",
    "#Reading all text files (research papers) in the directory\n",
    "for filename in gb.glob(directory + '*.txt'):\n",
    "    with open(filename, 'r', encoding='cp1252') as f:\n",
    "        filenum = re.search(r'\\d+', filename) #Getting only the decimal from the filename using regulax expression\n",
    "        if filenum:\n",
    "                document_list[int(filenum.group())] = (f.read().lower()) #Group function helps unpack the decimal value\n",
    "                originals.add(int(filenum.group()))\n",
    "                total_docs+=1\n",
    "\n",
    "stopwords = \"\"\n",
    "#Reading Stopwords Text File \n",
    "with open(\"Stopword-List.txt\", 'r') as f:\n",
    "        stopwords += f.read().strip() #Cleaning the String of any leading or trailing new line character\n",
    "stopwords = stopwords.replace(\" \", \"\") #Removing any extra whitespace characters\n",
    "stopwords = stopwords.replace('\\n', \" \") #Removing any new line character in between the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning data \n",
    "def clean_data(): #Gets rid of anything that is not in lowerecase alphabet set or a number\n",
    "    cleaned_data = defaultdict(str)\n",
    "    for docID in document_list:\n",
    "        string = document_list[docID]\n",
    "        cleaned_data[docID] = (re.sub(r'[^a-z]',\" \", string)) #Returns space seperated.\n",
    "    return cleaned_data\n",
    "\n",
    "document_list = clean_data() #Getting the cleaned data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "def tokenize(doc):\n",
    "    cleaned_doc = []\n",
    "    doc = list(doc.split()) #For whitespaced words\n",
    "    for word in doc:\n",
    "        if word not in stopwords: #Only including words that are not in our Stop Words File.\n",
    "            cleaned_doc.append(word)\n",
    "    return cleaned_doc\n",
    "\n",
    "token_list = defaultdict(list)\n",
    "for docID, doc in document_list.items():\n",
    "    cleaned_doc = tokenize(doc)\n",
    "    token_list[docID] = cleaned_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "from nltk import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer() #Using Built-in Stemmer\n",
    "\n",
    "stemmed_list = defaultdict(dict)\n",
    "for docID, doc in token_list.items():\n",
    "    stemmed_list[docID] = ([stemmer.stem(word) for word in doc]) #Creates a Stemmed List and Assigns it to its corresponding Document\n",
    "\n",
    "# stemmed_sw_list = defaultdict(list) \n",
    "# for docID, doc in tokens_with_stopword.items(): #Stemmed List including stopwords.\n",
    "#     stemmed_sw_list[docID] = [stemmer.stem(word) for word in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Term Frequency & Document Frequency\n",
    "from math import log10\n",
    "term_occur = defaultdict(set)\n",
    "term_freq = defaultdict(lambda: defaultdict(int))\n",
    "for docID, doc in stemmed_list.items():\n",
    "    for i in doc:\n",
    "        term_freq[docID][i]+=1 #Term Frequency of each term in its corresponding document\n",
    "        term_occur[i].add(docID)\n",
    "\n",
    "doc_freq = {}\n",
    "for key, value in term_occur.items():\n",
    "    doc_freq[key] = len(value)\n",
    "    # print(f\"Document Frequency of {key} --> {doc_freq[key]}\")\n",
    "\n",
    "#Inverse Document Frequency\n",
    "idf = {}\n",
    "for key, value in doc_freq.items():\n",
    "    idf[key] = log10(total_docs/value)\n",
    "    # print(f\"IDF of {key} -> {idf[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inverted Index\n",
    "inv_index = defaultdict(list)\n",
    "\n",
    "#TF-IDF Weighting\n",
    "tf_idf = defaultdict(lambda: defaultdict(float))\n",
    "for key, value in term_freq.items():\n",
    "    for term, freq in value.items():\n",
    "        tf_idf[term][key] = freq * idf[term]\n",
    "        inv_index[key].append(term)\n",
    "\n",
    "# print(inv_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Vector Space Model\n",
    "vsm = defaultdict(lambda: defaultdict(float))\n",
    "for key, values in inv_index.items():\n",
    "    doc_vec = {}\n",
    "    for i in values:\n",
    "        doc_vec[i] = (tf_idf[i][key]) #Building Document Vector. At each term, its tf-idf weight is appended.\n",
    "    sorted_doc_vec = dict(sorted(doc_vec.items(), key=lambda x: x[1], reverse=True)) #Sorting the document vector using its tf-idf weighting\n",
    "    vsm[key] = sorted_doc_vec #Adding document vector to its document number.\n",
    "# print(vsm[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "from math import sqrt\n",
    "\n",
    "def cosine_similarity(query, document):\n",
    "    dot_prod = sum(query.get(term, 0) * document.get(term, 0) for term in set(query) and set(document))\n",
    "    query_mag = sqrt(sum(v**2 for v in query.values()))\n",
    "    doc_mag = sqrt(sum(v**2 for v in document.values()))\n",
    "    if query_mag == 0 or doc_mag == 0:\n",
    "        return 0\n",
    "    return dot_prod / (query_mag * doc_mag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to preprocess raw query to the algorithm specific format.\n",
    "from collections import Counter\n",
    "def preproccess_query(raw_query: str):\n",
    "    raw_query = raw_query.lower()\n",
    "    c_query = (re.sub(r'[^a-z]',\" \", raw_query))\n",
    "    tokens = tokenize(c_query)\n",
    "    refined_query = Counter([stemmer.stem(i) for i in tokens])\n",
    "    return refined_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vsm_queries(query, alpha=0.03):\n",
    "    fine_query = preproccess_query(query)\n",
    "    ranked_documents = []\n",
    "    for docID, doc in vsm.items():\n",
    "        sim = cosine_similarity(fine_query, doc)\n",
    "        if sim >= alpha:\n",
    "            ranked_documents.append((docID, sim))\n",
    "    ranked_documents.sort(key=lambda x: x[1], reverse=True)\n",
    "    if len(ranked_documents):\n",
    "        return [tup[0] for tup in ranked_documents]\n",
    "    return None\n",
    "        \n",
    "# if __name__ == '__main__':\n",
    "#     query = input(\"Enter your Query: \")\n",
    "#     ranks = run_vsm_queries(query, 0.03)\n",
    "#     if ranks is None:\n",
    "#         print(\"No relevant documents found.\")\n",
    "#     else: \n",
    "#         for id, sim in ranks:\n",
    "#             print(f\"Document ID: {id} with Similarity: {sim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inverted Index\n",
    "class InvertedIndex:\n",
    "    def __init__(self, document: dict, totalDocuments: set):\n",
    "        self.originals = totalDocuments\n",
    "        self.document = document\n",
    "        self.index = defaultdict(set) #Dictionary of Set to get Document ID in the Set of each term\n",
    "    \n",
    "    def buildIndex(self):\n",
    "        for docID, doc in self.document.items():\n",
    "            for words in doc:\n",
    "                self.index[words].add(docID) \n",
    "        self.sortDoc()\n",
    "\n",
    "    #Helper Function to Sort Postings List    \n",
    "    def sortDoc(self):\n",
    "        for key, _ in self.index.items():\n",
    "            lst = list(self.index[key])\n",
    "            lst.sort()\n",
    "            self.index[key] = set(lst)\n",
    "\n",
    "    #Testing Function to Test Inverted Index\n",
    "    def displayIndex(self):\n",
    "        count = 0\n",
    "        for key, value in self.index.items():\n",
    "            print(f\"Term: {key} -> Posting List: {value}\")\n",
    "            count+=1\n",
    "        print(f\"Number of Terms: {count}\")\n",
    "\n",
    "    #Helper Function To Retrieve Postings List\n",
    "    def getPostingList(self, term):\n",
    "        return self.index[stemmer.stem(term)]\n",
    "    \n",
    "    #AND Function Helper Function\n",
    "    def Intersection(self, list1, list2):\n",
    "        if len(list1) < len(list2):\n",
    "            common_docs = [i for i in list1 if i in list2]\n",
    "        else:\n",
    "            common_docs = [i for i in list2 if i in list1]\n",
    "        \n",
    "        return sorted(set(common_docs))\n",
    "    \n",
    "    #NOT Operation Helper Function\n",
    "    def inversePostingList(self, w1):\n",
    "        list1 = self.getPostingList(w1)\n",
    "        inverseList = set()\n",
    "        for i in self.originals:\n",
    "            if i not in list1:\n",
    "                inverseList.add(i)\n",
    "                # print(type(i))\n",
    "\n",
    "        if len(inverseList) > 0:\n",
    "            return sorted(inverseList)\n",
    "        return None\n",
    "    \n",
    "    #OR Operation Helper Function\n",
    "    def union(self, list1, list2):\n",
    "        return sorted(set(list(list1)+list(list2)))\n",
    "    \n",
    "    #Processing Queries\n",
    "    def processQueries(self, words: list, op1_not = None, op2_not = None, op3_not = None, op1 = None, op2 = None):\n",
    "        list1 = set()\n",
    "        list2 = set()\n",
    "        list3 = set()\n",
    "        \n",
    "        if op1 == \"None\" and op2 == \"None\": #One Term Query Processing\n",
    "            if stemmer.stem[words[0]] not in self.index:\n",
    "                return None\n",
    "            print(\"here1\")\n",
    "            if op1_not != \"None\": #If Query has NOT Operator\n",
    "                return self.inversePostingList(words[0]) \n",
    "            else:\n",
    "                return self.getPostingList(words[0])\n",
    "        elif op2 == \"None\": #Two Term Query Processing\n",
    "            if stemmer.stem(words[0]) not in self.index:\n",
    "                return None\n",
    "            if stemmer.stem(words[1]) not in self.index:\n",
    "                return None\n",
    "            print(\"here2\")\n",
    "            if op1_not != \"None\":\n",
    "                list1 = self.inversePostingList(words[0]) #For NOT Operator\n",
    "            else:\n",
    "                list1 = self.getPostingList(words[0])\n",
    "            \n",
    "            if op2_not != \"None\":\n",
    "                list2 = self.inversePostingList(words[1]) #For NOT Operator\n",
    "            else:\n",
    "                list2 = self.getPostingList(words[1])\n",
    "            \n",
    "            if op1 == \"AND\":\n",
    "                return self.Intersection(list1, list2) #For AND Operator\n",
    "            elif op1 == \"OR\":\n",
    "                return self.union(list1, list2) #For OR Operator\n",
    "            \n",
    "        else: #Three Term Query Processing\n",
    "            if stemmer.stem(words[0]) not in self.index:\n",
    "                return None\n",
    "            if stemmer.stem(words[1]) not in self.index:\n",
    "                return None\n",
    "            if stemmer.stem(words[2]) not in self.index:\n",
    "                return None\n",
    "            print(\"here3\")\n",
    "            if op1_not != \"None\":\n",
    "                list1 = self.inversePostingList(words[0]) #For NOT Operator\n",
    "            else:\n",
    "                list1 = self.getPostingList(words[0])\n",
    "            \n",
    "            if op2_not != \"None\":\n",
    "                list2 = self.inversePostingList(words[1]) #For NOT Operator\n",
    "            else:\n",
    "                list2 = self.getPostingList(words[1])\n",
    "\n",
    "            if op3_not != \"None\":\n",
    "                list3 = self.inversePostingList(words[2]) #For NOT Operator\n",
    "            else:\n",
    "                list3 = self.getPostingList(words[2])\n",
    "\n",
    "            n = len(list1)\n",
    "            m = len(list2)\n",
    "            k = len(list3)\n",
    "            if (n+m) < (m+k): #Comparison to reduce the required operations to find the resultant list\n",
    "                if op1 == \"AND\":\n",
    "                    result1 = self.Intersection(list1, list2) #AND Operator\n",
    "                elif op1 == \"OR\":\n",
    "                    result1 = self.union(list1, list2) #OR Operator\n",
    "                \n",
    "                if op2 == \"AND\":\n",
    "                    return self.Intersection(result1, list3) #AND Operator\n",
    "                elif op2 == \"OR\":\n",
    "                    return self.union(result1, list3) #OR Operator\n",
    "            else:\n",
    "                if op2 == \"AND\":\n",
    "                    result1 = self.Intersection(list2, list3) #AND Operator\n",
    "                elif op2 == \"OR\":\n",
    "                    result1 = self.union(list2, list3) #OR Operator\n",
    "                \n",
    "                if op1 == \"AND\":\n",
    "                    return self.Intersection(list1, result1) #AND Operator\n",
    "                elif op1 == \"OR\":\n",
    "                    return self.union(list1, result1) #OR Operator    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positional Index\n",
    "class PositionalIndex:\n",
    "    def __init__(self):\n",
    "        self.posIndex = {}\n",
    "\n",
    "    #Helper Function for Retrieving Term Index List\n",
    "    def getTermIndexList(self, w1):\n",
    "        return self.posIndex[w1]\n",
    "\n",
    "    #Building Positional Index Here\n",
    "    def buildIndex(self):\n",
    "        for docID , tokens in stemmed_sw_list.items():\n",
    "            for i in range(len(tokens)):\n",
    "                if tokens[i] not in self.posIndex:\n",
    "                    self.posIndex[tokens[i]] = {}\n",
    "                if docID not in self.posIndex[tokens[i]]:\n",
    "                    self.posIndex[tokens[i]][docID] = set()\n",
    "                self.posIndex[tokens[i]][docID].add(i+1)\n",
    "    \n",
    "    #Processing Proximity Queries Here\n",
    "    def processQuery(self, words, distance): \n",
    "        w1 = stemmer.stem(words[0])\n",
    "        w2 = stemmer.stem(words[1])\n",
    "        \n",
    "        #Validating if words exist or not\n",
    "        if w1 not in self.posIndex: \n",
    "            return None\n",
    "        if w2 not in self.posIndex:\n",
    "            return None\n",
    "        \n",
    "        result = set()\n",
    "\n",
    "        #Getting Term Index List of Both Words\n",
    "        dict1 = self.getTermIndexList(w1)\n",
    "        dict2 = self.getTermIndexList(w2)\n",
    "        \n",
    "        #Processing the Dictionary of both\n",
    "        for key, value in dict1.items():\n",
    "            if key in list(dict2.keys()):\n",
    "                list1 = value\n",
    "                list2 = dict2[key]\n",
    "\n",
    "                for i in list1:\n",
    "                    for j in list2:\n",
    "                        if abs(i-j) <= distance:\n",
    "                            result.add(key)\n",
    "\n",
    "        result = list(result)\n",
    "        result.sort()\n",
    "\n",
    "        return result\n",
    "                \n",
    "                \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     pos_index = PositionalIndex() \n",
    "#     pos_index.buildIndex()   \n",
    "#     print(pos_index.processQuery([\"past\", \"research\"], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Driver Code including GUI\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "class InformationRetrievalSearch(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title(\"Rohan's Retrieval\")\n",
    "        \n",
    "        # Set window size\n",
    "        self.geometry(\"800x600\")\n",
    "\n",
    "        # Variables to store input values\n",
    "        self.term1_prox_value = tk.StringVar(value=None)\n",
    "        self.term2_prox_value = tk.StringVar(value=None)\n",
    "        self.term1_value = tk.StringVar(value=None)\n",
    "        self.term2_value = tk.StringVar(value=None)\n",
    "        self.term3_value = tk.StringVar(value=None)\n",
    "        self.not1_value = tk.StringVar(value=None)\n",
    "        self.not2_value = tk.StringVar(value=None)\n",
    "        self.not3_value = tk.StringVar(value=None)\n",
    "        self.operator1_value = tk.StringVar(value=None)\n",
    "        self.operator2_value = tk.StringVar(value=None)\n",
    "        self.proximity_value = tk.StringVar(value=None)\n",
    "        self.result = set()\n",
    "        self.pos_result = set()\n",
    "        \n",
    "        # Create notebook to hold multiple pages\n",
    "        self.notebook = ttk.Notebook(self)\n",
    "        self.notebook.pack(expand=True, fill=tk.BOTH)\n",
    "        \n",
    "        #Building Inverted Index as soon as the GUI is Launched\n",
    "        self.inv_index = InvertedIndex(stemmed_list, originals)\n",
    "        self.inv_index.buildIndex()\n",
    "\n",
    "        #Building Positional Index\n",
    "        self.pos_index = PositionalIndex()\n",
    "        self.pos_index.buildIndex()\n",
    "\n",
    "        # Add inverted index page\n",
    "        self.add_inverted_index_page()\n",
    "\n",
    "        # Add positional index page\n",
    "        self.add_positional_index_page()\n",
    "\n",
    "        #Add Vector Space Model Page\n",
    "        self.add_vsm_page()\n",
    "    \n",
    "    #Processing Inverted Index Queries\n",
    "    def processInvertedIndexQuery(self, output_text):\n",
    "        index = self.inv_index\n",
    "        words = [self.term1_value.get().lower(), self.term2_value.get().lower(), self.term3_value.get().lower()]\n",
    "        \n",
    "        #Validating Inputs\n",
    "        if self.not1_value.get() == \"\":\n",
    "            self.not1_value.initialize(None)\n",
    "        if self.not2_value.get() == \"\":\n",
    "            self.not2_value.initialize(None)\n",
    "        if self.not3_value.get() == \"\":\n",
    "            self.not3_value.initialize(None)\n",
    "        if self.operator1_value.get() == \"\":\n",
    "            self.operator1_value.initialize(None)\n",
    "        if self.operator2_value.get() == \"\":\n",
    "            self.operator2_value.initialize(None)\n",
    "\n",
    "        if words[0] == \"Enter term 1\":\n",
    "            words[0] = None\n",
    "        if words[1] == \"Enter term 2\":\n",
    "            words[1] = None\n",
    "        if words[2] == \"Enter term 3\":\n",
    "            words[2] = None\n",
    "\n",
    "        #Query Processing\n",
    "        self.result = index.processQueries(words, self.not1_value.get(), self.not2_value.get(), self.not3_value.get(), self.operator1_value.get(), self.operator2_value.get())\n",
    "        self.display_result(self.result, output_text)\n",
    "\n",
    "    #Inverted Index Page\n",
    "    def add_inverted_index_page(self):\n",
    "        inverted_index_frame = tk.Frame(self.notebook)\n",
    "        \n",
    "        #Dropdown for NOT operator before term 1\n",
    "        not_dropdown1 = ttk.Combobox(inverted_index_frame, values=[\"\", \"NOT\"], width=5, textvariable=self.not1_value)\n",
    "        not_dropdown1.pack(pady=5)\n",
    "        \n",
    "        #Term 1 input\n",
    "        term1_entry = tk.Entry(inverted_index_frame, width=30, textvariable=self.term1_value)\n",
    "        term1_entry.insert(0, \"Enter term 1\")\n",
    "        term1_entry.bind(\"<FocusIn>\", lambda event: self.clear_placeholder(event, term1_entry))\n",
    "        term1_entry.pack(pady=5)\n",
    "        \n",
    "        #Dropdown between term 1 and term 2\n",
    "        operator_dropdown1 = ttk.Combobox(inverted_index_frame, values=[\"\",\"AND\", \"OR\"], width=5, textvariable=self.operator1_value)\n",
    "        operator_dropdown1.pack(pady=5)\n",
    "        \n",
    "        #Dropdown for NOT operator before term 2\n",
    "        not_dropdown2 = ttk.Combobox(inverted_index_frame, values=[\"\", \"NOT\"], width=5, textvariable=self.not2_value)\n",
    "        not_dropdown2.pack(pady=5)\n",
    "        \n",
    "        # Term 2 input\n",
    "        term2_entry = tk.Entry(inverted_index_frame, width=30, textvariable=self.term2_value)\n",
    "        term2_entry.insert(0, \"Enter term 2\")\n",
    "        term2_entry.bind(\"<FocusIn>\", lambda event: self.clear_placeholder(event, term2_entry))\n",
    "        term2_entry.pack(pady=5)\n",
    "        \n",
    "        #Dropdown between term 2 and term 3\n",
    "        operator_dropdown2 = ttk.Combobox(inverted_index_frame, values=[\"\",\"AND\", \"OR\"], width=5, textvariable=self.operator2_value)\n",
    "        operator_dropdown2.pack(pady=5)\n",
    "\n",
    "        #Dropdown for NOT operator before term 3\n",
    "        not_dropdown1 = ttk.Combobox(inverted_index_frame, values=[\"\", \"NOT\"], width=5, textvariable=self.not3_value)\n",
    "        not_dropdown1.pack(pady=5)\n",
    "        \n",
    "        #Term 3 input\n",
    "        term3_entry = tk.Entry(inverted_index_frame, width=30, textvariable=self.term3_value)\n",
    "        term3_entry.insert(0, \"Enter term 3\")\n",
    "        term3_entry.bind(\"<FocusIn>\", lambda event: self.clear_placeholder(event, term3_entry))\n",
    "        term3_entry.pack(pady=5)\n",
    "        \n",
    "        \n",
    "        # Search button\n",
    "        inverted_search_button = tk.Button(inverted_index_frame, text=\"Search\", width=20, command=lambda: self.processInvertedIndexQuery(output_text))\n",
    "        inverted_search_button.pack(pady=10)\n",
    "\n",
    "        #Heading for Output Box\n",
    "        output_label = tk.Label(inverted_index_frame, text=\"Retrieved Documents\")\n",
    "        output_label.pack(pady=5)\n",
    "\n",
    "        #Output box\n",
    "        output_text = tk.Text(inverted_index_frame, height=10, width=70)\n",
    "        output_text.pack(pady=15)\n",
    "        output_text.insert(tk.END, \"Enter a Query.\")\n",
    "        output_text.config(state=\"disabled\")\n",
    "\n",
    "        self.notebook.add(inverted_index_frame, text=\"Boolean Queries\")\n",
    "\n",
    "    def processProximityQueries(self, output_text):\n",
    "            words = [self.term1_prox_value.get().lower(), self.term2_prox_value.get().lower()]\n",
    "            distance = int(self.proximity_value.get())\n",
    "            pos_index = self.pos_index\n",
    "            self.pos_result = pos_index.processQuery(words, distance)\n",
    "\n",
    "            self.display_result(self.pos_result, output_text)\n",
    "\n",
    "    #Positional Index Page\n",
    "    def add_positional_index_page(self):\n",
    "        positional_index_frame = tk.Frame(self.notebook)\n",
    "        \n",
    "        #Search bars for term 1 and term 2\n",
    "        positional_search_entry_1 = tk.Entry(positional_index_frame, width=50, textvariable=self.term1_prox_value)\n",
    "        positional_search_entry_1.insert(0, \"Enter term 1\")\n",
    "        positional_search_entry_1.bind(\"<FocusIn>\", lambda event: self.clear_placeholder(event, positional_search_entry_1))\n",
    "        positional_search_entry_1.pack(pady=5)\n",
    "        \n",
    "        positional_search_entry_2 = tk.Entry(positional_index_frame, width=50, textvariable=self.term2_prox_value)\n",
    "        positional_search_entry_2.insert(0, \"Enter term 2\")\n",
    "        positional_search_entry_2.bind(\"<FocusIn>\", lambda event: self.clear_placeholder(event, positional_search_entry_2))\n",
    "        positional_search_entry_2.pack(pady=5)\n",
    "\n",
    "        #Entry for proximity integer value\n",
    "        proximity_entry = tk.Entry(positional_index_frame, width=50, textvariable=self.proximity_value)\n",
    "        proximity_entry.insert(0, \"Enter proximity value\")\n",
    "        proximity_entry.bind(\"<FocusIn>\", lambda event: self.clear_placeholder(event, proximity_entry))\n",
    "        proximity_entry.pack(pady=5)\n",
    "        \n",
    "        #Search button\n",
    "        positional_search_button = tk.Button(positional_index_frame, text=\"Search\", width=20, command=lambda: self.processProximityQueries(output_text))\n",
    "        positional_search_button.pack(pady=10)\n",
    "        \n",
    "        #Heading for output box\n",
    "        output_label = tk.Label(positional_index_frame, text=\"Retrieved Documents\")\n",
    "        output_label.pack(pady=5)\n",
    "\n",
    "        #Output box\n",
    "        output_text = tk.Text(positional_index_frame, height=10, width=60)\n",
    "        output_text.pack(pady=10)\n",
    "        output_text.insert(tk.END, \"Enter a Query.\")\n",
    "        output_text.config(state=\"disabled\")\n",
    "\n",
    "\n",
    "        self.notebook.add(positional_index_frame, text=\"Proximity Queries\")\n",
    "    \n",
    "    #Vector Space Model\n",
    "    def add_vsm_page(self):\n",
    "        vsm_frame = tk.Frame(self.notebook)\n",
    "\n",
    "        # Textbox for entering terms for VSM query\n",
    "        query_textbox = tk.Text(vsm_frame, height=2, width=60)\n",
    "        query_textbox.pack(pady=10)\n",
    "\n",
    "        # Add a search button for VSM queries\n",
    "        vsm_search_button = tk.Button(vsm_frame, text=\"Search\", width=20, command=lambda: self.process_vsm_query(output_text, query_textbox))\n",
    "        vsm_search_button.pack(pady=10)\n",
    "        \n",
    "        # Heading for output box\n",
    "        output_label = tk.Label(vsm_frame, text=\"Retrieved Documents\")\n",
    "        output_label.pack(pady=5)\n",
    "\n",
    "        # Output box for displaying results\n",
    "        output_text = tk.Text(vsm_frame, height=10, width=60)\n",
    "        output_text.pack(pady=10)\n",
    "        output_text.insert(tk.END, \"Enter a Query.\")\n",
    "        output_text.config(state=\"disabled\")\n",
    "\n",
    "        # Add the VSM frame to the notebook\n",
    "        self.notebook.add(vsm_frame, text=\"Vector Space Model\")\n",
    "\n",
    "    def process_vsm_query(self, output_text, query_textbox):\n",
    "        # Get the query string from the textbox\n",
    "        query_string = query_textbox.get(\"1.0\", tk.END).strip()\n",
    "        \n",
    "        # Split the query string into individual terms\n",
    "        query_terms = str(query_string.split())\n",
    "\n",
    "        # Perform VSM query processing\n",
    "        vsm_result = run_vsm_queries(query_terms)  # Implement this method\n",
    "        \n",
    "        # Display VSM query results in the output text box\n",
    "        self.display_result(vsm_result, output_text)\n",
    "\n",
    "\n",
    "    def clear_placeholder(self, event, entry_widget):\n",
    "        if entry_widget.get() == \"Enter term 1\" or entry_widget.get() == \"Enter term 2\" or entry_widget.get() == \"Enter term 3\" or entry_widget.get() == \"Enter proximity value\":\n",
    "            entry_widget.delete(0, tk.END)\n",
    "\n",
    "    def display_result(self, result, output_text):\n",
    "        #Get search query and perform search\n",
    "        if result:\n",
    "            result_str = \"\\n\".join(map(str, result))\n",
    "        else:\n",
    "            result_str = \"No Documents Found....\"\n",
    "        \n",
    "        #Display result in the output box\n",
    "        output_text.config(state=\"normal\")\n",
    "        output_text.delete(\"1.0\", tk.END)  #Clear previous content\n",
    "        output_text.insert(tk.END, result_str)\n",
    "        output_text.config(state=\"disabled\")\n",
    "\n",
    "#Main Driver Code\n",
    "if __name__ == \"__main__\":\n",
    "    app = InformationRetrievalSearch()\n",
    "    app.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
